# -*- coding: utf-8 -*-
"""Housing_Price_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SIov4XjR7KWjBsqZ4Z27pl5suEuEy2wn
"""

###
# IMPORTING AND LOADING LIBRARIES
###

import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import OrdinalEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import FunctionTransformer
from sklearn.impute import SimpleImputer
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score,KFold, cross_validate
from sklearn.pipeline import Pipeline
from sklearn.ensemble import GradientBoostingRegressor

from sklearn.metrics import r2_score,mean_squared_error

plt.style.use('fivethirtyeight')

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings("ignore",category=matplotlib.MatplotlibDeprecationWarning)

###
# Loading train and test data
###

train_df = pd.read_csv("/content/train.csv")
test_df = pd.read_csv("/content/test.csv")
df = train_df.copy()
df.head()

df.shape

df.isnull().sum()[df.isnull().sum() >0].sort_values(ascending=False)

# Dropping columns with very high count of null values

removed_cols = ['PoolQC','MiscFeature','Alley','Fence']
df.drop(columns=removed_cols,inplace =True)

###
# PLOTTING COLUMNS THAT HAVE VERY HIGH NULL COUNTS
###

print(f"Skewness: { df['SalePrice'].skew() }")
sns.histplot(x = df['SalePrice'],kde=True)
plt.show()

# Log Transformation
print(f"Skewness: { (np.log(df['SalePrice'])).skew() }")
sns.histplot(x = np.log(df['SalePrice']),kde=True)
plt.show()

df['SalePrice'] = np.log(df['SalePrice'])

num_cols = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF', '2ndFlrSF','LowQualFinSF', 'GrLivArea',
           'GarageArea', 'WoodDeckSF','OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea','MiscVal','SalePrice']

plt.figure(figsize=(15,8))
sns.heatmap(df[num_cols].corr(numeric_only=True),annot=True, fmt=".2f")
plt.show()

# For Numerical Columns
def hist_box_scat_graph(columns_list,df,target_column='SalePrice'):
    '''
    columns_list: list of columns you want to plot.
    df: Dataframe from which columns to be plot.
    target_column : column against which you want to plot scatter plot.
    '''
    for col in columns_list:
        plt.figure(figsize=(15, 3))
        plt.title(col)

        plt.subplot(1,3,1)
        sns.histplot(x = df[col], kde=True)
        plt.xlabel(col)
        plt.ylabel('Frequency')

        plt.subplot(1,3,2)
        sns.boxplot(x=df[col])

        plt.subplot(1,3,3)
        sns.scatterplot(x=df[col],y=df[target_column])

        plt.show()
        plt.close()

### For Categorical Columns

def bar_box_pie_plot(cat_col_list,df,target_column = 'SalePrice'):
    '''
    columns_list: list of columns you want to plot.
    df: Dataframe from which columns to be plot.
    target_column : column against which you want to plot boxplot.
    '''
    for col in cat_col_list:
        temp = df[col].value_counts().reset_index()
        temp.columns = [col, 'Count']

        plt.figure(figsize=(15, 3))
        plt.title(col)

        plt.subplot(1,3,1)
        sns.barplot(temp,x=col,y='Count')
        plt.xticks(rotation=90)

        plt.subplot(1,3,2)
        sns.boxplot(df,x=col,y = target_column)
        plt.xticks(rotation=90)

        plt.subplot(1,3,3)
        plt.pie(x = temp['Count'],autopct='%.2f',labels=temp[col])
        plt.show()
        plt.close()

hist_box_scat_graph(num_cols,df)

for i in cols_remove:
    num_cols.remove(i)

temp_df = df[['LotFrontage','LotArea','SalePrice']].copy()
temp_df.drop([249, 313, 335, 706,934, 1298],inplace =True)

temp_df['LotFrontage'] = np.log1p(temp_df['LotFrontage'])
temp_df['LotArea'] = np.log1p(temp_df['LotArea'])

hist_box_scat_graph(['LotFrontage','LotArea'],temp_df)

sns.heatmap(temp_df.corr(numeric_only=True),annot=True, fmt=".2f")
plt.show()

outliers_rows = []
outliers_rows +=list(df[df['LotArea'] > 100000].index)
outliers_rows += list(df[df['TotalBsmtSF'] > 4000].index)

df.drop(outliers_rows,inplace = True)

# Log Transformation:
for i in ['LotArea', 'GrLivArea', 'MasVnrArea','WoodDeckSF','OpenPorchSF']:
    df[i] = np.log1p(df[i])


## Skewness:
for i in ['LotArea','TotalBsmtSF','GrLivArea', 'MasVnrArea','WoodDeckSF','OpenPorchSF']:
    print(f'Skewness of {i}: {df[i].skew()}')

removed_cols = ['PoolQC','MiscFeature','Alley','Fence']
removed_cols += ['LotFrontage']
df.drop(columns='LotFrontage',inplace = True)

TotalFullBaths = df['FullBath'] + df['BsmtFullBath']
TotalFullBaths = TotalFullBaths.rename('TotalFullBaths')
TotalHalfBaths = df['HalfBath'] + df['BsmtHalfBath']
TotalHalfBaths = TotalHalfBaths.rename('TotalHalfBaths')

miss_perc = (df.isnull().sum()/len(df)).sort_values(ascending=False) * 100
miss_perc[miss_perc > 0]

obj_cols = list(df.select_dtypes(include='object').columns)
print(obj_cols)

qual_cond_categories = [['Notav','Po','Fa','TA','Gd','Ex']]
qual_cond_list = ['ExterQual','ExterCond','BsmtQual','BsmtCond','HeatingQC','KitchenQual','FireplaceQu','GarageQual','GarageCond']
othr_odn_list = ['BsmtExposure','PavedDrive','GarageType','GarageFinish','LotShape']
othr_odn_cat = [['Notav','No','Mn','Av','Gd'],['N','P','Y'],['Notav','CarPort','Detchd','Basment','2Types','Attchd','BuiltIn'],['Notav','Unf','RFn','Fin'],['IR3','IR2','IR1','Reg']]

rem_cols = obj_cols[:]
for i in ['ExterQual','ExterCond','BsmtQual','BsmtCond','HeatingQC','KitchenQual','FireplaceQu','GarageQual','GarageCond','BsmtExposure','PavedDrive','GarageType','GarageFinish','LotShape']:
    rem_cols.remove(i)

transformer = ColumnTransformer(
    [('qual_cond_tnf',OrdinalEncoder(categories=qual_cond_categories * len(qual_cond_list)),qual_cond_list),
     ('othr_odn',OrdinalEncoder(categories = othr_odn_cat),othr_odn_list),
     ('rem_cols',OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1),rem_cols)],
    remainder='passthrough'
)

for i in ['GarageCond','GarageType','GarageFinish','GarageQual','BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2','MasVnrType','FireplaceQu']:
    df[i].fillna(value = 'Notav',inplace = True)

temp_df = df.reset_index(drop=True).copy()

X = temp_df[obj_cols][:]
y = temp_df.iloc[:,-1]

tnf_cols = qual_cond_list + othr_odn_list + rem_cols

X_tnf = pd.DataFrame(transformer.fit_transform(X),columns=tnf_cols)
temp_df[tnf_cols] = X_tnf

temp_df

temp_df.fillna(0,inplace=True)

X = temp_df.iloc[:,:-1]
y = temp_df.iloc[:,-1]
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)

rf = RandomForestRegressor(random_state=42)
rf.fit(X,y)
fi = rf.feature_importances_

fi_df = pd.DataFrame(list(zip(X.columns,fi *100))).sort_values(by=1,ascending=False).reset_index(drop=True)
fi_df

temp_df.drop(columns = ['Street','Utilities'],inplace = True)

pipe_xgb = Pipeline([('scaler', StandardScaler()), ('xgbr',XGBRegressor())])
pipe_gbm = Pipeline([('scaler', StandardScaler()),('gbm',GradientBoostingRegressor())])

kf = KFold(n_splits=5, shuffle=True, random_state=42)
scoring = ['r2', 'neg_root_mean_squared_error']

## XGBoostRegressor
xgb_scores = cross_validate(pipe_xgb, X, y, cv=kf, scoring=scoring,return_train_score = True)
print(f"R2: {np.mean(xgb_scores['test_r2']):.4f} ± {np.std(xgb_scores['test_r2']):.4f}")
print(f"RMSE: {-np.mean(xgb_scores['test_neg_root_mean_squared_error']):.4f} ± {np.std(xgb_scores['test_neg_root_mean_squared_error']):.4f}")

# Gradient Boosting
gbm_scores = cross_validate(pipe_gbm, X, y, cv=kf, scoring=scoring,return_train_score = True)
print(f"R2: {np.mean(gbm_scores['test_r2']):.4f} ± {np.std(gbm_scores['test_r2']):.4f}")
print(f"RMSE: {-np.mean(gbm_scores['test_neg_root_mean_squared_error']):.4f} ± {np.std(gbm_scores['test_neg_root_mean_squared_error']):.4f}")

main_feat= list(temp_df.columns)
for i in ['BsmtFullBath','FullBath','BsmtHalfBath','HalfBath']:
    main_feat.append(i)
main_feat.remove('SalePrice')

train_df.drop(outliers_rows,inplace = True)
train_df['BsmtExposure'].loc[948] = 'No'
train_df['BsmtFinType2'].loc[332] = 'Unf'
train_df.drop(1379,inplace = True)

class preprocess_df(BaseEstimator, TransformerMixin):
    def fit(self,X,y):
        return self

    def transform(self,X):
        tnf_df = self.dropper(X)
        tnf_df = self.imputer(tnf_df)
        tnf_df = self.feat_eng(tnf_df)
        tnf_df = self.log_tnf(tnf_df)
        return tnf_df

    def dropper(self,df):
        return df[main_feat][:]

    def imputer(self,df):
        ## fill columns with notav
        notav_cols = ['GarageCond','GarageType','GarageFinish','GarageQual','BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2','MasVnrType','FireplaceQu']
        for i in notav_cols:
            df[i].fillna(value = 'Notav',inplace = True)
        ## imputer zero in numerical columns
        num_cols = df.select_dtypes(include='number').columns
        for i in num_cols:
            df[i].fillna(value=0,inplace = True)
        obj_cols = df.select_dtypes(include='object').columns
        ## Fill categorical obj columns with most frequent(mode)
        for i in obj_cols:
            mod = df[i].mode()[0]
            df[i].fillna(value = mod,inplace = True)
        return df

    def feat_eng(self,df):
        TotalFullBaths = df['FullBath'][:] + df['BsmtFullBath'][:]
        TotalHalfBaths = df['HalfBath'][:] + df['BsmtHalfBath'][:]
        df.insert(loc=0,column='TotalFullBath',value=TotalFullBaths)
        df.insert(loc=0,column='TotalHalfBath',value=TotalHalfBaths)
        df.drop(columns=['FullBath','BsmtFullBath','HalfBath','BsmtHalfBath'],inplace = True)
        return df

    def log_tnf(self,df):
        for i in ['LotArea', 'GrLivArea', 'MasVnrArea','WoodDeckSF','OpenPorchSF']:
            df[i] = np.log1p(df[i])
        return df

rem_cols.remove('Street')
rem_cols.remove('Utilities')

odn_enc = ColumnTransformer(
    [('qual_cond_tnf',OrdinalEncoder(categories=qual_cond_categories * len(qual_cond_list)),qual_cond_list),
     ('othr_odn',OrdinalEncoder(categories = othr_odn_cat),othr_odn_list),
     ('rem_cols',OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1),rem_cols)],
    remainder='passthrough'
)

model = Pipeline(
    [('preprocesser',preprocess_df()),
    ('encoding',odn_enc),
    ('scaler',StandardScaler()),
    ('xgb_reg',XGBRegressor(tree_method="hist", device="cuda",eta=0.1,max_depth = 4,alpha = 0.31,min_child_weight=3,subsample=0.6))]
)

X = train_df.iloc[:,:-1]
y = np.log1p(train_df['SalePrice'])

model.fit(X,y)

ypreds = model.predict(test_df)

test_preds = np.expm1(ypreds)

test_id = test_df['Id'].values

submission = pd.DataFrame({'Id' : test_id, 'Saleprice': test_preds})

submission

# We do preprocessing, encoding and then perform XGB regression